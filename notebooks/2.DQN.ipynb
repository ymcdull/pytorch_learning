{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From:\n",
    "# http://pytorch.apachecn.org/cn/tutorials/intermediate/reinforcement_q_learning.html#sphx-glr-intermediate-reinforcement-q-learning-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# 设置 matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# 如果要使用 gpu 的话\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "Tensor = FloatTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.head = nn.Linear(448, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111dfcf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Scale(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "# This is based on the code from gym.\n",
    "screen_width = 600\n",
    "\n",
    "\n",
    "def get_cart_location():\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "\n",
    "def get_screen():\n",
    "    screen = env.render(mode='rgb_array').transpose(\n",
    "        (2, 0, 1))  # transpose into torch order (CHW)\n",
    "    # Strip off the top and bottom of the screen\n",
    "    screen = screen[:, 160:320]\n",
    "    view_width = 320\n",
    "    cart_location = get_cart_location()\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescare, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # 调整大小并添加批量维度 (BCHW)\n",
    "    return resize(screen).unsqueeze(0).type(Tensor)\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "\n",
    "model = DQN()\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.RMSprop(model.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        return model(\n",
    "            Variable(state, volatile=True).type(FloatTensor)).data.max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return LongTensor([[random.randrange(2)]])\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.FloatTensor(episode_durations)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_sync = 0\n",
    "\n",
    "\n",
    "def optimize_model():\n",
    "    global last_sync\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # 将betch转置 (详见 http://stackoverflow.com/a/19343/3343043).\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # 计算非最终状态的掩码并连接批处理元素s\n",
    "    non_final_mask = ByteTensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)))\n",
    "\n",
    "    # 我们不想通过预期的动作值反向传播, volatile 变量会临时将模型参数\n",
    "    # 'requires_grad' 更改为False！\n",
    "    non_final_next_states = Variable(torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None]),\n",
    "                                     volatile=True)\n",
    "    state_batch = Variable(torch.cat(batch.state))\n",
    "    action_batch = Variable(torch.cat(batch.action))\n",
    "    reward_batch = Variable(torch.cat(batch.reward))\n",
    "\n",
    "    # 计算 Q(s_t, a) - 模型计算出 Q(s_t), 然后我们选择某一栏动作执行\n",
    "    state_action_values = model(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # 对所有下一状态计算出 V(s_{t+1})\n",
    "    next_state_values = Variable(torch.zeros(BATCH_SIZE).type(Tensor))\n",
    "    next_state_values[non_final_mask] = model(non_final_next_states).max(1)[0]\n",
    "    # 此时我们不想让 volatile flag 混乱了我们的loss, 因此我们将其置为False\n",
    "    # 在此之后, 我们将会直接丢弃满足该变量, 并设 requires_grad=False\n",
    "    next_state_values.volatile = False\n",
    "    # 计算 Q 的期望值\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # 计算 Huber 损失\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "\n",
    "    # 优化模型\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in model.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1173bfa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "render() got an unexpected keyword argument 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4e5388304cd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Complete'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mioff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: render() got an unexpected keyword argument 'close'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1173bfa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_episodes = 20\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action[0, 0])\n",
    "        reward = Tensor([reward])\n",
    "\n",
    "        # 观察记录新状态\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # 将变化过程存到内存中\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # 转移到下一状态\n",
    "        state = next_state\n",
    "\n",
    "        # 对目标神经网络执行一步优化\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "env.render(close=True)\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
